import os
import time
import random
import threading
from http.server import HTTPServer, BaseHTTPRequestHandler
from telegram import Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes
from groq import Groq

# ======================
# CONFIG
# ======================
BOT_TOKEN = os.getenv("BOT_TOKEN")
GROQ_KEY = os.getenv("GROQ_API_KEY")

if not BOT_TOKEN:
    raise RuntimeError("âŒ BOT_TOKEN nÃ£o configurado")

if not GROQ_KEY:
    raise RuntimeError("âŒ GROQ_API_KEY nÃ£o configurado")

client = Groq(api_key=GROQ_KEY)

# ======================
# PORTA FAKE (RENDER FREE)
# ======================
PORT = int(os.getenv("PORT", 10000))

class PingHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.end_headers()
        self.wfile.write("Malu alive ğŸ’–".encode("utf-8"))

def run_dummy_server():
    server = HTTPServer(("0.0.0.0", PORT), PingHandler)
    server.serve_forever()

threading.Thread(target=run_dummy_server, daemon=True).start()

# ======================
# PERSONALIDADE MALU
# ======================
SYSTEM_PROMPT = """
VocÃª Ã© MALU, uma bot feminina em um grupo de amigos no Telegram.

Personalidade:
- EngraÃ§ada, simpÃ¡tica, educada, carinhosa
- Fala como uma amiga humana real
- Usa emojis moderadamente
- Humor leve, nunca ofensivo
- NÃ£o fala demais
- Nunca parece robÃ³tica

Regras:
- NÃƒO responda mensagens em reply
- NÃƒO interrompa conversas pessoais
- Entre na conversa apenas quando fizer sentido
- Seja leve, charmosa e carismÃ¡tica
"""

# ======================
# CONTROLE HUMANO
# ======================
last_response_time = {}
RESPONSE_COOLDOWN = 20
RESPONSE_CHANCE = 0.55

RANDOM_REACTIONS = [
    "HAHA vocÃªs sÃ£o caÃ³ticos demais ğŸ˜‚",
    "Esse grupo Ã© simplesmente perfeito ğŸ˜…ğŸ’–",
    "Eu lendo isso igual fofoca ğŸ‘€",
    "Amei essa energiaaaa âœ¨",
    "VocÃªs sÃ£o tudo ğŸ˜­ğŸ’",
    "Calmaaa, respira ğŸ˜Œ",
]

# ======================
# FUNÃ‡ÃƒO PRINCIPAL
# ======================
async def malu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text:
        return

    # âŒ NÃƒO RESPONDE REPLIES
    if update.message.reply_to_message:
        return

    chat_id = update.message.chat_id
    text = update.message.text.strip()
    now = time.time()

    # â³ ANTI FLOOD
    if chat_id in last_response_time:
        if now - last_response_time[chat_id] < RESPONSE_COOLDOWN:
            return

    # ğŸ² CHANCE HUMANA
    if random.random() > RESPONSE_CHANCE:
        return

    # ğŸ­ Ã€S VEZES REAGE SEM IA
    if random.random() < 0.15:
        await update.message.reply_text(random.choice(RANDOM_REACTIONS))
        last_response_time[chat_id] = now
        return

    try:
        res = client.chat.completions.create(
            model="llama3-70b-8192",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": text}
            ],
            temperature=0.9,
            max_tokens=160
        )

        reply = res.choices[0].message.content.strip()

        if len(reply) > 450:
            reply = reply[:450] + "..."

        await update.message.reply_text(reply)
        last_response_time[chat_id] = now

    except Exception as e:
        print("âŒ Groq error:", e)
        await update.message.reply_text("Ai buguei um pouquinho ğŸ˜… jÃ¡ volto!")

# ======================
# START BOT
# ======================
app = Application.builder().token(BOT_TOKEN).build()
app.add_handler(MessageHandler(filters.TEXT & filters.ChatType.GROUPS, malu))

print("ğŸ’– MALU ELITE ONLINE...")
app.run_polling()
